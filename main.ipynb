{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finvizfinance.screener.overview import Overview\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding \"undervalued\" stocks to invest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DCGO', 'HAFC', 'MTW', 'OPBK', 'STCN', 'TCBX']\n"
     ]
    }
   ],
   "source": [
    "def get_undervalued_stocks():\n",
    "    \"\"\"\n",
    "    Returns a list of tickers with:\n",
    "    \n",
    "    - Positive Operating Margin\n",
    "    - Debt-to-Equity ratio under 1\n",
    "    - Low P/B (under 1)\n",
    "    - Low P/E ratio (under 15)\n",
    "    - Low PEG ratio (under 1)\n",
    "    - Positive Insider Transactions\n",
    "    \"\"\"\n",
    "    foverview = Overview()\n",
    "\n",
    "    filters_dict = {'Debt/Equity':'Under 1', \n",
    "                    'PEG':'Low (<1)', \n",
    "                    'Operating Margin':'Positive (>0%)', \n",
    "                    'P/B':'Low (<1)',\n",
    "                    'P/E':'Low (<15)',\n",
    "                    'InsiderTransactions':'Positive (>0%)'}\n",
    "    \n",
    "    parameters = ['Exchange', 'Index', 'Sector', 'Industry', 'Country', 'Market Cap.',\n",
    "        'P/E', 'Forward P/E', 'PEG', 'P/S', 'P/B', 'Price/Cash', 'Price/Free Cash Flow',\n",
    "        'EPS growththis year', 'EPS growthnext year', 'EPS growthpast 5 years', 'EPS growthnext 5 years',\n",
    "        'Sales growthpast 5 years', 'EPS growthqtr over qtr', 'Sales growthqtr over qtr',\n",
    "        'Dividend Yield', 'Return on Assets', 'Return on Equity', 'Return on Investment',\n",
    "        'Current Ratio', 'Quick Ratio', 'LT Debt/Equity', 'Debt/Equity', 'Gross Margin',\n",
    "        'Operating Margin', 'Net Profit Margin', 'Payout Ratio', 'InsiderOwnership', 'InsiderTransactions',\n",
    "        'InstitutionalOwnership', 'InstitutionalTransactions', 'Float Short', 'Analyst Recom.',\n",
    "        'Option/Short', 'Earnings Date', 'Performance', 'Performance 2', 'Volatility', 'RSI (14)',\n",
    "        'Gap', '20-Day Simple Moving Average', '50-Day Simple Moving Average',\n",
    "        '200-Day Simple Moving Average', 'Change', 'Change from Open', '20-Day High/Low',\n",
    "        '50-Day High/Low', '52-Week High/Low', 'Pattern', 'Candlestick', 'Beta',\n",
    "        'Average True Range', 'Average Volume', 'Relative Volume', 'Current Volume',\n",
    "        'Price', 'Target Price', 'IPO Date', 'Shares Outstanding', 'Float']\n",
    "    \n",
    "    foverview.set_filter(filters_dict=filters_dict)\n",
    "    df_overview = foverview.screener_view()\n",
    "    if not os.path.exists('out'): #ensures you have an 'out' folder ready\n",
    "        os.makedirs('out')\n",
    "    df_overview.to_csv('out/Overview.csv', index=False)\n",
    "    tickers = df_overview['Ticker'].to_list()\n",
    "    return tickers\n",
    "\n",
    "print(get_undervalued_stocks())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using BERT to perform a sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from transformers import TFBertForSequenceClassification, BertTokenizer, pipeline\n",
    "from goose3 import Goose\n",
    "from requests import get\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\GuilhermeChicharoFro\\Desktop\\Ai-Sentiment-Analysis\\myenv\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:AutoGraph could not transform <function infer_framework at 0x0000017670E2D8A0> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function infer_framework at 0x0000017670E2D8A0> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:From c:\\Users\\GuilhermeChicharoFro\\Desktop\\Ai-Sentiment-Analysis\\myenv\\Lib\\site-packages\\tensorflow\\python\\autograph\\converters\\directives.py:126: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\GuilhermeChicharoFro\\Desktop\\Ai-Sentiment-Analysis\\myenv\\Lib\\site-packages\\tensorflow\\python\\autograph\\converters\\directives.py:126: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "5/5 [==============================] - 69s 4s/step - loss: 1.0549 - accuracy: 0.3750 - val_loss: 0.7378 - val_accuracy: 0.7000\n",
      "Epoch 2/3\n",
      "5/5 [==============================] - 4s 817ms/step - loss: 0.6555 - accuracy: 0.8500 - val_loss: 0.5944 - val_accuracy: 0.9000\n",
      "Epoch 3/3\n",
      "5/5 [==============================] - 4s 797ms/step - loss: 0.4099 - accuracy: 0.9500 - val_loss: 0.5789 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./finetuned_finbert\\\\tokenizer_config.json',\n",
       " './finetuned_finbert\\\\special_tokens_map.json',\n",
       " './finetuned_finbert\\\\vocab.txt',\n",
       " './finetuned_finbert\\\\added_tokens.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Prepare Training Data\n",
    "data = {\n",
    "    'text': [\n",
    "        'The stock market is doing great!',\n",
    "        'The company is facing a lawsuit.',\n",
    "        'The new product launch was a success.',\n",
    "        'There are concerns about the CEO\\'s health.',\n",
    "        'The quarterly earnings exceeded expectations.',\n",
    "        'The stock price fell after the earnings report.',\n",
    "        'Investors are worried about the recent changes in management.',\n",
    "        'The company announced a new partnership.',\n",
    "        'There are rumors of a potential merger.',\n",
    "        'The CEO gave a positive outlook for the future.',\n",
    "        'The company\\'s sales increased by 20% last quarter.',\n",
    "        'The company faced a significant security breach.',\n",
    "        'The economy is showing signs of recovery.',\n",
    "        'The new infrastructure project was well received by the market.',\n",
    "        'Investors are worried about rising inflation.',\n",
    "        'The company launched an innovative product in the market.',\n",
    "        'The CEO announced his retirement.',\n",
    "        'The merger between the two companies was approved.',\n",
    "        'The company lost a major contract bid.',\n",
    "        'The stock prices surged after the acquisition news.',\n",
    "        'The new marketing strategy failed to attract customers.',\n",
    "        'The company received a prestigious industry award.',\n",
    "        'The competitor\\'s new product is outperforming in the market.',\n",
    "        'The company announced layoffs due to restructuring.',\n",
    "        'The quarterly report showed a decline in revenue.',\n",
    "        'The company is under investigation for fraud.',\n",
    "        'The new CEO is expected to bring major changes.',\n",
    "        'The company reported record profits this year.',\n",
    "        'The stock price remained stable despite market fluctuations.',\n",
    "        'The company is expanding its operations internationally.',\n",
    "        'The new software update received positive reviews.',\n",
    "        'The company is struggling to keep up with competitors.',\n",
    "        'The new branch opening was delayed due to regulatory issues.',\n",
    "        'The company secured a lucrative government contract.',\n",
    "        'The stock price dropped sharply after the CEO\\'s resignation.',\n",
    "        'The company is investing heavily in renewable energy.',\n",
    "        'The company\\'s new ad campaign went viral.',\n",
    "        'The company is facing supply chain disruptions.',\n",
    "        'The product recall affected the company\\'s reputation.',\n",
    "        'The company received a large investment from a venture capital firm.',\n",
    "        'The company is expected to benefit from the new trade agreement.',\n",
    "        'The new partnership is expected to drive growth.',\n",
    "        'The company is facing increased competition in the market.',\n",
    "        'The stock price hit a new all-time high.',\n",
    "        'The company announced a dividend increase.',\n",
    "        'The company is closing underperforming stores.',\n",
    "        'The new product failed to meet sales expectations.',\n",
    "        'The company is focusing on improving customer satisfaction.',\n",
    "        'The company\\'s research and development spending increased.',\n",
    "        'The company is planning to launch an IPO next year.'\n",
    "    ],\n",
    "    'label': [\n",
    "        2, 0, 2, 0, 2, 0, 0, 2, 1, 2, \n",
    "        2, 0, 1, 2, 0, 2, 0, 2, 0, 2, \n",
    "        0, 2, 0, 0, 0, 0, 2, 2, 1, 2, \n",
    "        2, 0, 0, 2, 0, 2, 2, 0, 0, 2, \n",
    "        2, 2, 0, 2, 2, 0, 0, 2, 2, 2\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(df['text'], df['label'], test_size=0.2)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "# Tokenize the texts\n",
    "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts.tolist(), truncation=True, padding=True)\n",
    "\n",
    "# Convert encodings to TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    ")).batch(8)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_labels\n",
    ")).batch(8)\n",
    "\n",
    "# Step 2: Fine-Tune the Model\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"ProsusAI/finbert\", num_labels=3)  # Assuming 3 sentiment classes\n",
    "\n",
    "# Define the optimizer, loss, and metrics\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy')]\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset, epochs=3, validation_data=val_dataset)\n",
    "\n",
    "# Save the Fine-Tuned Model\n",
    "model.save_pretrained(\"./finetuned_finbert\")\n",
    "tokenizer.save_pretrained(\"./finetuned_finbert\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_news_sentiment(ticker):\n",
    "    \"\"\"\n",
    "    Returns a Pandas dataframe of the given ticker's most recent news article headlines,\n",
    "    with the overal sentiment of each article.\n",
    "\n",
    "    Args:\n",
    "        ticker (string)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: {'Date', 'Article title', Article sentiment'}\n",
    "    \"\"\"\n",
    "    ticker_news = yf.Ticker(ticker)\n",
    "    news_list = ticker_news.get_news()\n",
    "    extractor = Goose()\n",
    "    pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
    "    data = []\n",
    "    for dic in news_list:\n",
    "        title = dic['title']\n",
    "        response = get(dic['link'])\n",
    "        article = extractor.extract(raw_html=response.content)\n",
    "        text = article.cleaned_text\n",
    "        date = article.publish_date\n",
    "        if len(text) > 512:\n",
    "            data.append({'Date':f'{date}',\n",
    "                         'Article title':f'{title}',\n",
    "                         'Article sentiment':'NaN too long'})\n",
    "        else:\n",
    "            results = pipe(text)\n",
    "            #print(results)\n",
    "            data.append({'Date':f'{date}',\n",
    "                         'Article title':f'{title}',\n",
    "                         'Article sentiment':results[0]['label']})\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "def generate_csv(ticker):\n",
    "    get_ticker_news_sentiment(ticker).to_csv(f'out/{ticker}.csv', index=False)\n",
    "\n",
    "undervalued = get_undervalued_stocks()\n",
    "for ticker in undervalued:\n",
    "    generate_csv(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
